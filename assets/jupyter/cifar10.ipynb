{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6d61e3d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-18T22:54:54.840247Z",
     "iopub.status.busy": "2025-02-18T22:54:54.839890Z",
     "iopub.status.idle": "2025-02-18T22:54:55.623410Z",
     "shell.execute_reply": "2025-02-18T22:54:55.622541Z"
    },
    "papermill": {
     "duration": 0.790285,
     "end_time": "2025-02-18T22:54:55.625611",
     "exception": false,
     "start_time": "2025-02-18T22:54:54.835326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/checkpoint/checkpoint (7) 2.pth\n",
      "/kaggle/input/checkpoint-2/checkpoint (10).pth\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36719f5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T22:54:55.632951Z",
     "iopub.status.busy": "2025-02-18T22:54:55.632226Z",
     "iopub.status.idle": "2025-02-18T22:55:08.664093Z",
     "shell.execute_reply": "2025-02-18T22:55:08.663149Z"
    },
    "papermill": {
     "duration": 13.037878,
     "end_time": "2025-02-18T22:55:08.666502",
     "exception": false,
     "start_time": "2025-02-18T22:54:55.628624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "cuda:0\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:03<00:00, 44073594.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import v2\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.__version__)\n",
    "#print(torch.version.cuda)\n",
    "print(device)\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "    #transforms.v2.AugMix(),\n",
    "    transforms.RandomHorizontalFlip(1),\n",
    "    #transforms.RandomVerticalFlip(),\n",
    "    #transforms.RandomRotation(15),  # Random rotation between -15 to 15 degrees\n",
    "    #transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "transform_1 = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "#mixup = torchvision.transforms.v2.Mixup(num_classes=10)\n",
    "\n",
    "trainset_1 = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainset_2 = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_1)\n",
    "trainset = torch.utils.data.ConcatDataset([trainset_1,trainset_2])\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_1)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False, num_workers=4)\n",
    "\n",
    "\n",
    "# Shuffle the data in the existing DataLoader\n",
    "reshuffled_train_loader = torch.utils.data.DataLoader(trainloader.dataset, batch_size=trainloader.batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7ed681d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T22:55:08.678646Z",
     "iopub.status.busy": "2025-02-18T22:55:08.677882Z",
     "iopub.status.idle": "2025-02-18T22:55:08.691829Z",
     "shell.execute_reply": "2025-02-18T22:55:08.690939Z"
    },
    "papermill": {
     "duration": 0.021991,
     "end_time": "2025-02-18T22:55:08.693783",
     "exception": false,
     "start_time": "2025-02-18T22:55:08.671792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def res(input_channel):\n",
    "    block = nn.Sequential(\n",
    "          nn.Conv2d(input_channel,input_channel,3, padding = 1, bias=False),\n",
    "          nn.BatchNorm2d(input_channel),\n",
    "          nn.ReLU(True),\n",
    "          nn.Conv2d(input_channel,input_channel,3, padding = 1, bias=False),\n",
    "          nn.BatchNorm2d(input_channel),\n",
    "        )\n",
    "    \n",
    "    return nn.Sequential(*block)\n",
    "\n",
    "def conv_block(input_channel, output_channel, filter_size = 3,padding = 1):\n",
    "    block = nn.Sequential(\n",
    "          nn.Conv2d(input_channel,output_channel,filter_size, stride = 2, padding = padding, bias = False),\n",
    "          nn.BatchNorm2d(output_channel),\n",
    "          nn.ReLU(True),\n",
    "          nn.Conv2d(output_channel,output_channel,filter_size, stride = 1, padding = padding, bias = False),\n",
    "          nn.BatchNorm2d(output_channel),\n",
    "        )\n",
    "    \n",
    "    return nn.Sequential(*block)\n",
    "\n",
    "def start(input_channel, output_channel, filter_size = 3, stride = 1, padding = 1):\n",
    "    block = nn.Sequential(\n",
    "          nn.Conv2d(input_channel,output_channel,filter_size, stride = stride, padding = padding, bias = False),\n",
    "          nn.BatchNorm2d(output_channel),\n",
    "          nn.ReLU(True),\n",
    "        )\n",
    "    \n",
    "    return nn.Sequential(*block)\n",
    "\n",
    "def downsample(input_channel, output_channel):\n",
    "    block = nn.Sequential(\n",
    "          nn.Conv2d(input_channel,output_channel,1, stride = 2, bias = False),\n",
    "          nn.BatchNorm2d(output_channel),\n",
    "        )\n",
    "    \n",
    "    return nn.Sequential(*block)\n",
    "\n",
    "\n",
    "class resnet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(resnet18, self).__init__()\n",
    "        self.conv1 = start(3, 64)\n",
    "        self.pool_1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.res1_1 = res(64)\n",
    "        self.res1_2 = res(64)\n",
    "        \n",
    "        self.conv2 = conv_block(64, 128, 3, padding = 1)\n",
    "        self.sample_1 = downsample(64, 128)\n",
    "        self.res2_1 = res(128)\n",
    "        \n",
    "        self.conv3 = conv_block(128, 256, 3, padding = 1)\n",
    "        self.res3_1 = res(256)\n",
    "        self.sample_2 = downsample(128, 256)\n",
    "      \n",
    "        self.conv4 = conv_block(256, 512, 3, padding = 1)\n",
    "        self.res4_1 = res(512)\n",
    "        self.sample_3 = downsample(256, 512)\n",
    "        self.drop = nn.Dropout()\n",
    "        \n",
    "        self.averagepool = nn.AdaptiveAvgPool2d(output_size = (1, 1))\n",
    "        self.fc1 = nn.Linear(512, 10)   #how many labels are needed in this task?\n",
    "        # self.fc = nn.Linear(512 * 16 * 16, 512)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        #x = self.pool_1(x)\n",
    "        x = F.relu(self.res1_1(x) + x)\n",
    "        x = F.relu(self.res1_2(x) + x)\n",
    "        \n",
    "        \n",
    "        x = F.relu(self.conv2(x) + self.sample_1(x))\n",
    "        x = F.relu(self.res2_1(x) + x)\n",
    "\n",
    "\n",
    "        x = F.relu(self.conv3(x) + self.sample_2(x))\n",
    "        x = F.relu(self.res3_1(x) + x)\n",
    "\n",
    "\n",
    "        x = F.relu(self.conv4(x) + self.sample_3(x))\n",
    "        x = F.relu(self.res4_1(x) + x)\n",
    "\n",
    "        # x = x.reshape((-1, 512*16*16))\n",
    "        x = self.averagepool(x)\n",
    "        # x = self.fc(x)\n",
    "        x = x.reshape((-1, 512))\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "763d8cd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T22:55:08.705643Z",
     "iopub.status.busy": "2025-02-18T22:55:08.705275Z",
     "iopub.status.idle": "2025-02-18T22:55:09.012027Z",
     "shell.execute_reply": "2025-02-18T22:55:09.011239Z"
    },
    "papermill": {
     "duration": 0.31508,
     "end_time": "2025-02-18T22:55:09.014166",
     "exception": false,
     "start_time": "2025-02-18T22:55:08.699086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = resnet18()\n",
    "# net = torchvision.models.resnet18(num_classes=10)\n",
    "# net.conv1 = nn.Conv2d(1, model.conv1.weight.shape[0], 3, 1, 1, bias = False)\n",
    "# net.maxpool = nn.MaxPool2d(kernel_size = 1, stride = 1, padding = 0)\n",
    "\n",
    "# PATH = \"model_path\"\n",
    "# net.load_state_dict(torch.load(PATH)['state_dict'])\n",
    "net.to(device)  # gpu/ cpu\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "max_lr = 0.1\n",
    "epochs = 100\n",
    "optimizer = optim.SGD(net.parameters(), lr = max_lr, weight_decay = 0.0001, momentum = 0.9) \n",
    "grad_clip = 0.001\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = epochs*len(trainloader))\n",
    "criterion = criterion.cuda()\n",
    "# sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n",
    "#                                                 steps_per_epoch=len(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c2b0fdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T22:55:09.025201Z",
     "iopub.status.busy": "2025-02-18T22:55:09.024939Z",
     "iopub.status.idle": "2025-02-18T22:55:09.031700Z",
     "shell.execute_reply": "2025-02-18T22:55:09.030780Z"
    },
    "papermill": {
     "duration": 0.014465,
     "end_time": "2025-02-18T22:55:09.033605",
     "exception": false,
     "start_time": "2025-02-18T22:55:09.019140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "def mixup_data(x, y, alpha=1.0, use_cuda=True):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbeb3560",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T22:55:09.044884Z",
     "iopub.status.busy": "2025-02-18T22:55:09.044199Z",
     "iopub.status.idle": "2025-02-19T00:34:35.289609Z",
     "shell.execute_reply": "2025-02-19T00:34:35.288301Z"
    },
    "papermill": {
     "duration": 5966.258015,
     "end_time": "2025-02-19T00:34:35.296602",
     "exception": false,
     "start_time": "2025-02-18T22:55:09.038587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.299 | Accuracy: 36.902 | lr: 0.099975\n",
      "Accuracy of the network on the 10000 test images: 71.510000%\n",
      "Train Loss: 0.255 | Accuracy: 91.083 | lr: 0.097044\n",
      "Train Loss: 0.103 | Accuracy: 96.421 | lr: 0.089508\n",
      "Accuracy of the network on the 10000 test images: 86.760000%\n",
      "Train Loss: 0.086 | Accuracy: 96.983 | lr: 0.078104\n",
      "Train Loss: 0.069 | Accuracy: 97.602 | lr: 0.063950\n",
      "Accuracy of the network on the 10000 test images: 87.830000%\n",
      "Train Loss: 0.050 | Accuracy: 98.293 | lr: 0.048429\n",
      "Train Loss: 0.031 | Accuracy: 98.978 | lr: 0.033063\n",
      "Accuracy of the network on the 10000 test images: 89.300000%\n",
      "Train Loss: 0.009 | Accuracy: 99.710 | lr: 0.019355\n",
      "Train Loss: 0.000 | Accuracy: 99.998 | lr: 0.008646\n",
      "Accuracy of the network on the 10000 test images: 91.660000%\n",
      "Train Loss: 0.000 | Accuracy: 100.000 | lr: 0.001985\n",
      "Finished Training last_learning_rate 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_accu, train_losses = [], []\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct=0\n",
    "    total=0\n",
    "    \n",
    "    #for inputs, labels in combined_data:\n",
    "    \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device) # inputs, labels = data\n",
    "        if epoch <= 2/epochs:\n",
    "            inputs, labels_a, labels_b, lam = mixup_data(inputs, labels, 0.2)\n",
    "       \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        if epoch <= 2/epochs:\n",
    "            loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)\n",
    "        else:\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_value_(net.parameters(), grad_clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_loss =running_loss/len(trainloader)\n",
    "    accu=100.*correct/total\n",
    "\n",
    "    train_accu.append(accu)\n",
    "    train_losses.append(train_loss)\n",
    "    if epoch % 10 == 0:\n",
    "        my_lr = scheduler.get_last_lr()[0]\n",
    "        avg_accu = sum(train_accu) / len(train_accu)\n",
    "        avg_loss = sum(train_losses) / len(train_losses)\n",
    "        print('Train Loss: %.3f | Accuracy: %.3f | lr: %f'%(avg_loss,avg_accu, my_lr))\n",
    "        train_accu, train_losses = [], []\n",
    "        \n",
    "    if epoch % 20 == 0:\n",
    "        net.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                outputs = net(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        accuracy = 100 * correct / total\n",
    "        print('Accuracy of the network on the 10000 test images: {:.6f}%'.format(accuracy))\n",
    "        net.train()\n",
    "        \n",
    "        \n",
    "    \n",
    "my_lr = scheduler.get_last_lr()[0]\n",
    "print('Finished Training', \"last_learning_rate\", my_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22ff1f09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T00:34:35.310723Z",
     "iopub.status.busy": "2025-02-19T00:34:35.309834Z",
     "iopub.status.idle": "2025-02-19T00:34:37.702856Z",
     "shell.execute_reply": "2025-02-19T00:34:37.701607Z"
    },
    "papermill": {
     "duration": 2.402276,
     "end_time": "2025-02-19T00:34:37.704743",
     "exception": false,
     "start_time": "2025-02-19T00:34:35.302467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 91.180000%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# dataiter = iter(testloader)\n",
    "# images, labels = next(dataiter)\n",
    "\n",
    "# images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "# outputs = net(images)\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print('Accuracy of the network on the 10000 test images: {:.6f}%'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ccdc11f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T00:34:37.718054Z",
     "iopub.status.busy": "2025-02-19T00:34:37.717703Z",
     "iopub.status.idle": "2025-02-19T00:34:38.097783Z",
     "shell.execute_reply": "2025-02-19T00:34:38.096947Z"
    },
    "papermill": {
     "duration": 0.389225,
     "end_time": "2025-02-19T00:34:38.099994",
     "exception": false,
     "start_time": "2025-02-19T00:34:37.710769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint = {'model': resnet18(),\n",
    "              'state_dict': net.state_dict(),\n",
    "              'optimizer' : optimizer.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 3981778,
     "sourceId": 6934361,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3982025,
     "sourceId": 6934729,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30580,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5989.213224,
   "end_time": "2025-02-19T00:34:40.603054",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-18T22:54:51.389830",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
